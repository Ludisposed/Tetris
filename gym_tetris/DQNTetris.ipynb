{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "from envs.tetris_env import TetrisEnv\n",
    "\n",
    "env = TetrisEnv()\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(24, input_shape=env.state_size, activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(24, activation='relu'))\n",
    "model.add(Dense(env.action_size, activation='linear'))\n",
    "model.compile(loss='mse', optimizer=Adam(lr=learning_rate))\n",
    "\n",
    "memory = deque(maxlen=2000)\n",
    "gamma = 0.95    \n",
    "epsilon = 1.0  # exploration rate\n",
    "epsilon_min = 0.01\n",
    "epsilon_decay = 0.995"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 1 0 0]\n",
      " [0 1 1 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "[[[0 1 1 0 0]\n",
      "  [0 1 1 0 0]\n",
      "  [0 0 0 0 0]\n",
      "  [0 0 0 0 0]\n",
      "  [0 0 0 0 0]\n",
      "  [0 0 0 0 0]\n",
      "  [0 0 0 0 0]\n",
      "  [0 0 0 0 0]\n",
      "  [0 0 0 0 0]\n",
      "  [0 0 0 0 0]]]\n",
      "(1, 10, 5)\n",
      "Observing Finished\n"
     ]
    }
   ],
   "source": [
    "observetime = 500\n",
    "ob = env.reset()\n",
    "print(ob)\n",
    "state = np.expand_dims(ob, axis=0) \n",
    "print(state)\n",
    "print(state.shape)\n",
    "done = False\n",
    "for t in range(observetime):\n",
    "    if np.random.rand() <= epsilon:\n",
    "        action = np.random.randint(0, env.action_size, size=1)[0]\n",
    "    else:\n",
    "        Q = model.predict(state)          # Q-values predictions\n",
    "        action = np.argmax(Q)             # Move with highest Q-value is the chosen one\n",
    "    observation_new, reward, done, info = env.step(action)     # See state of the game, reward... after performing the action\n",
    "    state_new = np.expand_dims(observation_new, axis=0)          # (Formatting issues)\n",
    "    memory.append((state, action, reward, state_new, done))         # 'Remember' action and consequence\n",
    "    state = state_new         # Update state\n",
    "    if done:\n",
    "        observation = env.reset()           # Restart game if it's finished\n",
    "        state = np.expand_dims(observation, axis=0)     # (Formatting issues) Making the observation the first element of a batch of inputs \n",
    "        \n",
    "print('Observing Finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[[0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [0, 1, 1, 0, 0],\n",
      "        [0, 1, 1, 0, 0],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1],\n",
      "        [0, 0, 0, 0, 1],\n",
      "        [0, 0, 0, 1, 1]]]), 2, 0, array([[[0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [0, 1, 1, 0, 0],\n",
      "        [0, 1, 1, 0, 0],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1],\n",
      "        [0, 0, 0, 0, 1],\n",
      "        [0, 0, 0, 1, 1]]]), False)\n",
      "Learning Finished\n"
     ]
    }
   ],
   "source": [
    "mb_size = 50\n",
    "minibatch = random.sample(memory, mb_size)                              # Sample some moves\n",
    "print(minibatch[10])\n",
    "inputs_shape = (mb_size,) + state.shape[1:]\n",
    "inputs = np.zeros(inputs_shape)\n",
    "targets = np.zeros((mb_size, env.action_size))\n",
    "\n",
    "for i in range(0, mb_size):\n",
    "    state = minibatch[i][0]\n",
    "    action = minibatch[i][1]\n",
    "    reward = minibatch[i][2]\n",
    "    state_new = minibatch[i][3]\n",
    "    done = minibatch[i][4]\n",
    "    \n",
    "# Build Bellman equation for the Q function\n",
    "    inputs[i:i+1] = np.expand_dims(state, axis=0)\n",
    "    targets[i] = model.predict(state)\n",
    "    Q_sa = model.predict(state_new)\n",
    "    \n",
    "    if done:\n",
    "        targets[i, action] = reward\n",
    "    else:\n",
    "        targets[i, action] = reward + gamma * np.max(Q_sa)\n",
    "\n",
    "# Train network to output the Q function\n",
    "    model.train_on_batch(inputs, targets)\n",
    "print('Learning Finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game ended! Total reward: 0\n"
     ]
    }
   ],
   "source": [
    "observation = env.reset()\n",
    "state = np.expand_dims(observation, axis=0)\n",
    "done = False\n",
    "tot_reward = 0.0\n",
    "while not done:\n",
    "    Q = model.predict(state)        \n",
    "    action = np.argmax(Q)         \n",
    "    observation, reward, done, info = env.step(action)\n",
    "    state = np.expand_dims(observation, axis=0)   \n",
    "    tot_reward += reward\n",
    "print('Game ended! Total reward: {}'.format(reward))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
